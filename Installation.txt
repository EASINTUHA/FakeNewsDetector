
**Note**: Model files (`xgb_model.pkl`, `tfidf.pkl`, `meta_learner.pkl`, `tokenizer.pkl`, `bert_model.pkl`) are hosted on Google Drive due to GitHubâ€™s file size limits. See [Model Files](#model-files) for download instructions.

## Installation
1. **Clone the Repository**:
   ```bash
   git clone https://github.com/EasinTuha/FakeNewsDetector.git
   cd FakeNewsDetector

2. Create and activate a virtual environment:
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
3. Install Dependencies:
   pip install -r requirements.txt

4. Install Dependencies:
    pip install -r requirements.txt

5. Download Model Files:
    pip install gdown
    gdown https://drive.google.com/uc?id=your-xgb-model-id -O xgb_model.pkl
    gdown https://drive.google.com/uc?id=your-tfidf-id -O tfidf.pkl
    gdown https://drive.google.com/uc?id=your-meta-learner-id -O meta_learner.pkl
    gdown https://drive.google.com/uc?id=your-tokenizer-id -O tokenizer.pkl
    gdown https://drive.google.com/uc?id=your-bert-model-id -O bert_model.pkl

Prepare the Dataset:
    import pandas as pd
    fake = pd.read_csv('Fake.csv')
    fake['label'] = 'FAKE'
    real = pd.read_csv('True.csv')
    real['label'] = 'REAL'
    data = pd.concat([fake, real], ignore_index=True)
    data.to_csv('news_dataset.csv', index=False)
